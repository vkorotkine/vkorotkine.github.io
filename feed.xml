<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://vkorotkine.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://vkorotkine.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-08-05T19:17:59+00:00</updated><id>https://vkorotkine.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">filtering updates on lie groups</title><link href="https://vkorotkine.github.io/blog/2025/filtering_lie_groups/" rel="alternate" type="text/html" title="filtering updates on lie groups"/><published>2025-07-16T00:00:00+00:00</published><updated>2025-07-16T00:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2025/filtering_lie_groups</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2025/filtering_lie_groups/"><![CDATA[<p>$\require{boldsymbol}$ Robot navigation is the task of determining a robot state from noisy sensor measurements, and therefore involves statistics and errors. However, our robot states often involve rotations, which raises questions on how we add and subtract rotations. We have to reconsider addition, subtraction, integration, and so on. We need Lie groups (some <a href="/assets/pdf/notes/lie_group_doc.pdf">notes</a> on Lie groups, and they are also covered in <d-cite key="barfoot2024state"></d-cite> and <d-cite key="sola2021microlietheorystate"></d-cite>).</p> <p>In this post I specifically focus on how we move gaussians around on Lie groups. Our robot belief is typically a gaussian. In cases where there are no rotations, and our robot state lives in a vectorspace where everything is nice. The robot state $\mathbf{x}$ is updated, typically through a Kalman filter correction step where the belief is conditioned on a received measurement ( see <d-cite key="sarkka2023bayesian"></d-cite> for detailed expressions ). The initial robot belief is a gaussian $\mathcal{N}(\mathbf{0}, \check{\mathbf{P}})$, that is then updated to $\mathcal{N}(\hat{\mathbf{x}}, \hat{\mathbf{P}})$. </p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/vectorspace_distribution_update-480.webp 480w,/assets/img/blogs/vectorspace_distribution_update-800.webp 800w,/assets/img/blogs/vectorspace_distribution_update-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blogs/vectorspace_distribution_update.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The nice vectorspace case. </div> <p>For the Lie group case, the state now lives on a manifold and is denoted $\mathcal{X}$. Notions of addition and subtraction are allowed in the Lie algebra, and in the <strong>tangent</strong> spaces defined at each $\mathcal{X}$. State beliefs are now represented as <strong>concentrated</strong> gaussians, where $\mathcal{X}=\bar{\mathcal{X}} \oplus \boldsymbol{\xi}, \quad \boldsymbol{\xi} \sim \mathcal{N}(\mathbf{0}, \mathbf{P})$. The gaussian lives in the tangent space and the distribution over the manifold is defined by its relationship to the tangent space. There are now two steps that must be done to update the robot state. First, in the initial state belief’s tangent space, the gaussian $\check{\boldsymbol{\xi}}$ distributed as $\mathcal{N}(\mathbf{0}, \check{\mathbf{P}})$ is updated to $\mathcal{N}(\bar{\boldsymbol{\xi}}, \bar{\mathbf{P}})$. This is done by writing the measurement model in terms of $\boldsymbol{\xi}$ and carrying out the standard Kalman filter updates on $\boldsymbol{\xi}$. This yields a distribution over $\boldsymbol{\xi}$ with a nonzero mean $\bar{\boldsymbol{\xi}}$. However, when we use concentrated gaussians, we want a distribution of the form $\mathcal{X}=\hat{\mathcal{X}} \oplus \boldsymbol{\xi}, \quad \boldsymbol{\xi} \sim \mathcal{N}(\mathbf{0}, \hat{\mathbf{P}})$, that has a zero mean for $\boldsymbol{\xi}$. We want our robot state belief to be at a given updated state $\hat{\mathcal{X}}$, without any strange tangent space additions.</p> <p>This whole process is illustrated in the following picture. </p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/manifold_distribution_update-480.webp 480w,/assets/img/blogs/manifold_distribution_update-800.webp 800w,/assets/img/blogs/manifold_distribution_update-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blogs/manifold_distribution_update.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The more complicated Lie group case. </div> <p>The question is then, what are $\hat{\mathcal{X}}$ and $\hat{\mathbf{P}}$? The key point is that the distributions given by $\mathcal{X}=\check{\mathcal{X}}\oplus \hat{\boldsymbol{\xi}}, \quad \hat{\boldsymbol{\xi}}\sim \mathcal{N}(\bar{\boldsymbol{\xi}}, \bar{\mathbf{P}})$ and $\mathcal{X}=\hat{\mathcal{X}}\oplus \boldsymbol{\xi}, \quad \boldsymbol{\xi}\sim \mathcal{N}(\mathbf{0}, \hat{\mathbf{P}})$ are the <strong>same</strong> distribution, just expressed in different tangent spaces of the manifold.</p> <p>We can therefore do a bit of math to manipulate $\mathcal{X}=\check{\mathcal{X}}\oplus \hat{\boldsymbol{\xi}}, \quad \hat{\boldsymbol{\xi}}\sim \mathcal{N}(\bar{\boldsymbol{\xi}}, \bar{\mathbf{P}})$.</p> <p> \begin{align*} \mathcal{X} &amp;= \check{\mathcal{X}} \oplus \check{\boldsymbol{\xi}}, \quad \check{\boldsymbol{\xi}} \sim \mathcal{N}(\bar{\boldsymbol{\xi}}, \bar{\mathbf{P}}) \\ &amp;= \check{\mathcal{X}} \oplus (\bar{\boldsymbol{\xi}} + \tilde{\boldsymbol{\xi}}), \quad \tilde{\boldsymbol{\xi}} \sim \mathcal{N}(0, \bar{\mathbf{P}}) \\ &amp;\approx \left( \check{\mathcal{X}} \oplus \bar{\boldsymbol{\xi}} \right) \oplus \underbrace{ \left. \frac{D(\mathcal{X} \oplus \boldsymbol{\tau})}{D\boldsymbol{\tau}} \right|_{\bar{\boldsymbol{\xi}}} }_{\mathbf{J}_{\tilde{\boldsymbol{\xi}}}} \tilde{\boldsymbol{\xi}}, \quad \tilde{\boldsymbol{\xi}} \sim \mathcal{N}(0, \bar{\mathbf{P}}) \\ &amp;= \hat{\mathcal{X}} \oplus \boldsymbol{\xi}, \quad \boldsymbol{\xi} \sim \mathcal{N}(0, \mathbf{J}_{\tilde{\boldsymbol{\xi}}} \bar{\mathbf{P}} \mathbf{J}_{\tilde{\boldsymbol{\xi}}}^\top) \end{align*} </p> <p>The crucial step comes in the third line, where we use the Lie group Jacobian of the plus operation, which is the same as the group Jacobian <d-cite key="sola2021microlietheorystate"></d-cite>. This Jacobian accounts for the difference in the tangent spaces at $\check{\mathcal{X}}$ and $\hat{\mathcal{X}}$. This explains the presence of the Jacobian in Lie group filter estimation codes such as in <a href="https://github.com/decargroup/navlie/blob/main/navlie/filters.py"> our lab’s navlie library. </a> For a small update, where $\tilde{\boldsymbol{\xi}}$ is small, this Jacobian is close to identity. However, for larger updates, neglecting it can cause inaccuracies in the updated covariance $\hat{\mathbf{P}}$.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[moving gaussians around curves]]></summary></entry><entry><title type="html">reflections on icra 2025</title><link href="https://vkorotkine.github.io/blog/2025/icra/" rel="alternate" type="text/html" title="reflections on icra 2025"/><published>2025-05-27T00:00:00+00:00</published><updated>2025-05-27T00:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2025/icra</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2025/icra/"><![CDATA[<p>The 2025 International Conference on Robotics and Automation (ICRA) this year was my first robotics conference experience after a few years of graduate school, held in Atlanta, Georgia. There were a lot of worries about getting there, given the current border tensions with our southern neighbour. In our case, they were completely unfounded - 3 short questions (Where are you going? What for? What conference?) and we were on our merry three-hour flight to Atlanta, a land of many highways and, surprisingly, a downtown that is quite nice, though a bit empty.</p> <p>It was an absolute privilege to interact with folks of the highest caliber in the field, and humbling to realize the size of the robotics community. There are truly a lot of smart people.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/icra2-480.webp 480w,/assets/img/blogs/icra2-800.webp 800w,/assets/img/blogs/icra2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blogs/icra2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/icra1-480.webp 480w,/assets/img/blogs/icra1-800.webp 800w,/assets/img/blogs/icra1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blogs/icra1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/icra3-480.webp 480w,/assets/img/blogs/icra3-800.webp 800w,/assets/img/blogs/icra3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blogs/icra3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Left to right: 1) First day at ICRA! 2) Sweet mother of open source, one of my favorite of this conference. From Kostas Alexis' talk. 3) Departing ICRA! See y'all in Vienna next year. </div> <p>The main takeaway, for me, that was repeated many times is to find the problem before the solution. Research in robotics can broadly be split into two categories. The first is “Top-Down”, where one tries to solve a real-world problem, and encounters issues later on that motivate a solution, which is the published. The second is “Bottom-Up”, where a mathematical insight is formulated first, and is then applied to different problems to see where it makes an impact. In practice, both approaches are needed. However, the bottom-up approach can often lead to “solutions that are looking for a problem”. It may not be too hard to remix existing mathematical ideas, but it can be quite hard to answer the question of “where will this actually make an impact?”. Tessa Lau gave a keynote on starting a robotics company in construction, and she reiterated that she looked for the problem <strong>before</strong> having a solution in mind. Of course, the reality is more nuanced. Sometimes an algorithm needs to be developed before the hardware is ready for it. Sometimes the quest for pure understanding is worth it in and of itself. However, to solve current real-world problems, it does seem that the academic needs to understand the problem <strong>before</strong> proposing the solution, by playing around with the system or working with an industrial partner. That being said, building in proper mathematical fundamentals into the proposed algorithms is still necessary to avoid “hacks” and make the system more robust.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/icra4-480.webp 480w,/assets/img/blogs/icra4-800.webp 800w,/assets/img/blogs/icra4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blogs/icra4.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/icra5-480.webp 480w,/assets/img/blogs/icra5-800.webp 800w,/assets/img/blogs/icra5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blogs/icra5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/icra6-480.webp 480w,/assets/img/blogs/icra6-800.webp 800w,/assets/img/blogs/icra6-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blogs/icra6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> More fun slides! Some challenges in mining robotics (Josh Marshall's workshop talk), and a shoutout to MomoCon that was happening at the same time as the conference. </div> <p>The second takeaway, while we all “know” this before going to a conference, robotics is an insanely broad and interdisciplinary field. ICRA had 7000 attendees and tens of talks going on in parallel throughout the day. The topics are varied, and, outside of my own narrow field it was quite hard to follow what was going on. In practice, it is also a very hard field. In a talk on agriculture robotics by Guillermo Pita Gil from Burro, he reiterated on the 80/20 rule. It is not too hard to build a product that works 80% of the time, as a demo, but getting those last 20% is extremely important and takes up 80% of the time to iron out the edge cases. This leads me to conclude that robotics specialists themselves will likely not be automated anytime soon, and there are plenty of problems to be solved :). </p>]]></content><author><name></name></author><summary type="html"><![CDATA[coffee break pastries were excellent]]></summary></entry><entry><title type="html">outlier rejection in nonlinear least squares</title><link href="https://vkorotkine.github.io/blog/2025/robust_loss_triggs/" rel="alternate" type="text/html" title="outlier rejection in nonlinear least squares"/><published>2025-05-12T00:00:00+00:00</published><updated>2025-05-12T00:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2025/robust_loss_triggs</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2025/robust_loss_triggs/"><![CDATA[ <p>In robotics, before anything else, the robot must estimate its <strong>state</strong>. An aerial vehicle must know its position, velocity, and heading before planning its path and creating a control law to follow it. An autonomous vehicle must know its velocity and the position of surrounding vehicles. Even a Roomba vacuum cleaner must know its location relative to the household cat in order to avoid an early demise at the hands of General Mittens. The <strong>state</strong> is thus whatever quantity of interest must be estimated for subsequent safe, reliable robot operation.</p> <p>Furthermore, the state is never known perfectly but rather <strong>estimated</strong> from sensor measurements, which are themselves imperfect. An accelerometer is corrupted by noise; a camera can suffer from motion blur; feature points on images may be incorrectly associated across frames to yield outliers. The problem is thus statistical in nature, and is often solved in a Maximum A Posteriori optimization framework, which takes the form of a nonlinear least squares problem. For “well-behaved” problems, where there are no outliers, Gaussian sensor models are used. In cases where outliers are present, robust losses are used to address the effect of the outliers’ high residuals on the solution quality.</p> <h1 id="nonlinear-least-squares">Nonlinear Least Squares</h1> <p>For Gaussian sensor models, the Maximum A Posteriori problem takes the nonlinear least squares form</p> <p> \begin{align} \hat{\mathbf{x}}&amp;=\text{argmin}_{\mathbf{x}} J(\mathbf{x}) = \text{argmin}_{\mathbf{x}} \sum_{i=1}^N \frac{1}{2} \mathbf{e}_i^T(\mathbf{x}) \mathbf{e}_i(\mathbf{x}), \end{align} </p> <p>where each $\mathbf{e}_i(\mathbf{x})$ is a nonlinear, vector function of the state $\mathbf{x}$, and usually corresponds to the difference between <strong><em>expected</em></strong> (based on the sensor model) and <strong><em>actual</em></strong> value of the $i$’th received measurement.</p> <p>The Newton optimization update at an iterate $\mathbf{x}^k$ is derived by minimizing a quadratic expansion expanded around the current iterate to yield</p> <p> \begin{align} \frac{\partial J}{\partial \mathbf{x} \partial \mathbf{x}^T} \Delta \mathbf{x} = -\frac{\partial J}{\partial \mathbf{x}^T}. \end{align} </p> <p>For the nonlinear-least-squares form of the loss $J(\mathbf{x})$, the Jacobian and Hessian become</p> <p> \begin{align} \frac{\partial J}{\partial \mathbf{x}^T} &amp;= \sum_{i=1}^N \frac{\partial J}{\partial \mathbf{e}_i} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}} = \sum_{i=1}^N \mathbf{e}_i^T \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}}, \\ \frac{\partial J}{\partial \mathbf{x} \partial \mathbf{x}^T} &amp;= \sum_{i=1}^N \left(\frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}} +\sum_{j=1}^{n_{e_i}} e_{i,j} \frac{\partial ^2 e_{i,j}}{\partial \mathbf{x} \partial \mathbf{x}^T} \right). \end{align} </p> <p>The second term in the Hessian sum is neglected to yield the Gauss-Newton update,</p> <p> \begin{align} \left(\sum_{i=1}^N \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}}\right) \Delta \mathbf{x} &amp;= \sum_{i=1}^N \mathbf{e}_i^T \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}}. \end{align} </p> <p>Typically we see all the error terms stacked into one big error, which yields a cleaner expression. However, for the sake of the robust loss derivation later on, we will keep them separated.</p> <p>As an aside, the convenient way to derive/check vector derivative identities is through expanding the matrix operation as a sum, carrying out the differentiation, and reassembling the output as a matrix expression. For example, the Jacobian of the quadratic form $\mathbf{e}^T \mathbf{e}$ may be derived by writing the definition of the Jacobian, and keeping in mind that we are working with a scalar such that it only has one row,</p> <p> \begin{align} \left . \frac{\partial \mathbf{e}^T \mathbf{e}}{\partial \mathbf{e}} \right|_{1j} &amp;= \frac{\partial}{\partial e_j} \sum_{i=1}^N e_i^2 = 2e_j, \end{align} </p> <p>which may be reassembled back into matrix form as</p> <p> \begin{align} \frac{\partial \mathbf{e}^T \mathbf{e}}{\partial \mathbf{e}} &amp;= 2\mathbf{e}^T. \end{align} </p> <h1 id="robust-loss">Robust Loss</h1> <p>In the case of robust losses, a robust loss $\rho_i: \mathbb{R}\rightarrow \mathbb{R}$ is assigned to each quadratic form $f_i=\frac{1}{2}\mathbf{e}_i^T\mathbf{e}_i$, which downweighs the effects of very high residuals. See <d-cite key="Barron17"></d-cite> for examples of robust loss functions. The Maximum A Posteriori problem is</p> <p> \begin{align} \hat{\mathbf{x}}&amp;=\text{argmin}_{\mathbf{x}} J(\mathbf{x}) = \text{argmin}_{\mathbf{x}} \sum_{i=1}^N \rho_i\left(\frac{1}{2}\mathbf{e}_i^T(\mathbf{x}) \mathbf{e}_i(\mathbf{x})\right) \end{align} </p> <p>The Jacobian of the loss is given by</p> <p> \begin{align} \frac{\partial J}{\partial \mathbf{x}^T} &amp;= \sum_{i=1}^N \frac{\partial J}{\partial \mathbf{e}_i} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}} = \sum_{i=1}^N\frac{\partial \rho_i}{\partial f_i}\mathbf{e}_i^T \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}}, \end{align} </p> <p>while the Hessian of the loss is given by</p> <p> \begin{align} \frac{\partial J}{\partial \mathbf{x} \partial \mathbf{x}^T} &amp;= \left( \frac{\partial}{\partial \mathbf{x}} \frac{\partial J}{\partial \mathbf{x}^T}\right)^T \\ &amp;= \left( \frac{\partial}{\partial \mathbf{x}} \sum_{i=1}^N \left( \frac{\partial \rho_i}{\partial f_i} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \mathbf{e}_i \right) \right)^T. \end{align} </p> <p>The derivative of the summand is obtained by a double application of the product rule, such that</p> <p> \begin{align} \frac{\partial}{\partial \mathbf{x}} \left( \frac{\partial \rho_i}{\partial f_i} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \mathbf{e}_i \right) &amp;= \frac{\partial}{\partial \mathbf{x}} \left(\frac{\partial \rho_i}{\partial f_i}\right) \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \mathbf{e}_i + \frac{\partial \rho_i}{\partial f_i} \left( \left( \frac{\partial}{\partial \mathbf{x}} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \right) \mathbf{e}_i + \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}} \right). \end{align} </p> <p>The key step in the Gauss-Newton iteration, which is carried over to the robust loss case, is in neglecting the second order derivatives of $\mathbf{e}_i$, such that $\frac{\partial}{\partial \mathbf{x}} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T}\approx \mathbf{0}$. Furthermore, the chain rule must be applied since since $\frac{\partial \rho_i}{\partial f_i}$ is itself a function of $\mathbf{x}$. This yields</p> <p> \begin{align} \frac{\partial}{\partial \mathbf{x}} \left( \frac{\partial \rho_i}{\partial f_i} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \mathbf{e}_i \right) &amp;= \frac{\partial}{\partial \mathbf{x}} \left(\frac{\partial \rho_i}{\partial f_i}\right) \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \mathbf{e}_i + \frac{\partial \rho_i}{\partial f_i} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}} \\ &amp;= \frac{\partial^2 \rho_i}{\partial f_i^2}\mathbf{e}_i^T \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \mathbf{e}_i + \frac{\partial \rho_i}{\partial f_i} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}}. \end{align} </p> <p>The overall Hessian is obtained by substituting the summand expression we just derived back into the sum,</p> <p> \begin{align} \frac{\partial J}{\partial \mathbf{x} \partial \mathbf{x}^T} &amp;= \left( \frac{\partial}{\partial \mathbf{x}} \frac{\partial J}{\partial \mathbf{x}^T}\right)^T \\ &amp;= \sum_{i=1}^N \frac{\partial^2 \rho_i}{\partial f_i^2}\mathbf{e}_i^T \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \mathbf{e}_i + \frac{\partial \rho_i}{\partial f_i} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}}. \end{align} </p> <p>The first term in the sum is called the <strong>Triggs correction</strong> <d-cite key="triggs1999bundle"></d-cite>. Neglecting it yields the iteratively reweighted least squares approach, where the Newton step is given by</p> <p> \begin{align} \sum_{i=1}^N \frac{\partial \rho_i}{\partial f_i} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}^T} \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}} \Delta \mathbf{x} &amp;= \sum_{i=1}^N\frac{\partial \rho_i}{\partial f_i}\mathbf{e}_i^T \frac{\partial \mathbf{e}_i}{\partial \mathbf{x}} \end{align} </p> <p>Comparing this expression to the Gauss-Newton case clarifies why it is called iteratively reweighted least squares. For each factor with a robust loss, we just consider the <em>non-weighted</em> error, and then just weigh it by $\sqrt{\frac{\partial \rho_i}{\partial f_i}}$, which yields exactly the nonlinear-least-squares update for the robust loss case we just derived. This is done for every factor separately. We can notice that if only one factor is used, the $\sqrt{\frac{\partial \rho_i}{\partial f_i}}$’s cancel out.</p> <h1 id="remarks">Remarks</h1> <p>Different robust losses may be used, and correspond to specific heavy-tailed distributions if we work “backward” to the MAP problem from the negative log-likelihood. A Cauchy loss corresponds to a Cauchy distribution assumed on sensor noise. However, the motivation for using robust losses is usually not any kind of rigorous statistical argument. We do not consider the statistical properties of erroneous feature associations across camera frames to determine the “right” robust loss. Rather, we use trial and error. It works because it works, and because we have nice methods for solving the resulting problem. This somewhat echoes a theme I’ve seen on Ben Recht’s substack. We often work with given models not because they are the most accurate or rigorous ones. Rather, we work with them because we are able to solve them. Afterward, we can try to justify why these models correspond to reality.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[an aesthetic derivation]]></summary></entry><entry><title type="html">getting openvins up and running with ros2</title><link href="https://vkorotkine.github.io/blog/2025/openvins-ros2/" rel="alternate" type="text/html" title="getting openvins up and running with ros2"/><published>2025-04-23T00:00:00+00:00</published><updated>2025-04-23T00:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2025/openvins-ros2</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2025/openvins-ros2/"><![CDATA[<h1 id="quickstart">Quickstart</h1> <p>Following the installation instructions <a href="https://docs.openvins.com/gs-installing.html">for installing OpenVINS with ROS 2 </a>. Following the ROS 2 <a href="https://docs.openvins.com/gs-tutorial.html#gs-tutorial-ros2">for installing OpenVINS with ROS 2 </a>. OpenVINS tutorial for running on EuRoC dataset. Running RViz using ROS 2 instead of ROS1. Note that simply running <code class="language-plaintext highlighter-rouge">rviz</code> from the command line like for ROS 1 will not work. Instead, do not install anything extra and run</p> <p>Specifically for the EuRoC example from OpenVINS,</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ros2 run rviz2 rviz2 -d /home/vassili/projects/openvins_workspace/catkin_ws_ov/src/open_vins/ov_msckf/launch/display_ros2.rviz
</code></pre></div></div> <p>where the global path is used (for now), since relative paths didn’t seem to be able to find the display file. Checking the <a href="https://docs.ros.org/en/humble/Tutorials/Intermediate/RViz/RViz-User-Guide/RViz-User-Guide.html#install-or-build-rviz"> ROS 2 guide for RViz </a> is handy.<br/> Then, as per the OpenVINS documentation,</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ros2 launch ov_msckf subscribe.launch.py config:=euroc_mav
ros2 bag play V1_01_easy.db3
</code></pre></div></div> <p>which are to be run in different terminals.</p> <h1 id="vs-code-intellisense-for-ros">VS Code Intellisense for ROS</h1> <p>To have the IntelliSense working for Python ROS packages, such as launch files, make sure to run VS Code as <code class="language-plaintext highlighter-rouge">code</code> from a terminal where the ROS setup has been sourced. <a href="https://robotics.stackexchange.com/questions/97707/how-can-i-make-vs-code-recognize-ros2-python-packages "> Source. </a> Furthermore, even though ROS installs its own versions of Eigen and OpenCV, I found that I had to install them separately to be able to point VS Code’s <code class="language-plaintext highlighter-rouge">includePath</code> to their libraries and have IntelliSense work properly.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt install libeigen3-dev
sudo apt install libopencv-dev
</code></pre></div></div> <p>After which the following <code class="language-plaintext highlighter-rouge">cpp_properties.json</code> file does the trick,</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    "configurations": [
        {
            "name": "Linux",
            "includePath": [
                "${workspaceFolder}/**", 
                "/usr/local/include/Eigen/**", 
                "/usr/include/opencv4/**", 
                ""/opt/ros/humble/**"
            ],
            "defines": [],
            "compilerPath": "/usr/bin/gcc",
            "cStandard": "c17",
            "cppStandard": "gnu++17",
            "intelliSenseMode": "linux-gcc-x64"
        }
    ],
    "version": 4
}
</code></pre></div></div> <p>There is also the following <a href="https://docs.ros.org/en/jazzy/How-To-Guides/Setup-ROS-2-with-VSCode-and-Docker-Container.html "> guide for using VS Code with ROS 2 and Docker. </a></p> <h1 id="evaluation">Evaluation</h1> <p>We now run the EuRoC dataset such that we can do the full algorithm evaluation.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>colcon build
source install/setup.bash # from workspace directory
ros2 launch ov_msckf subscribe.launch.py config:=euroc_mav # from workspace directory
ros2 bag play V1_01_easy.db3 # from data bag directory
ros2 launch ov_eval record.launch.py  # from workspace directory
</code></pre></div></div> <p>Debugging:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ros2 node info /pose_to_file # check that subscription is actually created 
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[notes on getting stuff running]]></summary></entry><entry><title type="html">discretization of continuous-time noise and process models</title><link href="https://vkorotkine.github.io/blog/2025/discrete-time-noise/" rel="alternate" type="text/html" title="discretization of continuous-time noise and process models"/><published>2025-03-20T00:00:00+00:00</published><updated>2025-03-20T00:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2025/discrete-time-noise</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2025/discrete-time-noise/"><![CDATA[<p>Physical systems are continuous. However, we work with discrete-time models that are amenable to digital computers. Therefore, we create continuous models of the physical systems that we then discretize.</p> <p>This becomes particularly interesting in the case of sensor noise, since there is a randomness that needs to be modeled. Typically we use white noise models. However, while the discrete-time white noise model is fairly straightforward (a Gaussian distribution for every noise sample), the continuous-time model is really not, and deriving the transition from continuous to discrete time for white noise is nuanced.</p> <p>A key aspect in this dilemma is that it’s hard to decouple the dynamics of the system we are considering from the random process noise properties. For instance, a gyroscope may have some continuous noise characteristics of its own. Yet, when we consider discrete-time properties, we need to look at the effect of time, and thus the overall system dynamics. This is only really tractable for linear systems (and thus, linearizations).</p> <p>The post is split into three parts. The first part on random processes essentially covers terminology. We go over why the term power spectral density is used interchangeably with continuous-time covariance. The second part covers the “Linearize then Discretize” method, which obtains discretizations by lumping in the effects of system dynamics with effect of random process noise. The first and second parts are essentially summaries of relevant parts of Sec. 4.3.2, 4.4, 4.7 of <d-cite key="farrell2008navigation"></d-cite>. The third part is where things get really interesting. We consider continuous to discrete time noise “in a vacuum” and try to decouple the effect of system dynamics from the random process noise. There is a commonly used formula, which yields good results in practice, but as far there is no completely satisfying way to derive it from first principles. We go through some approaches that have been proposed and discuss them. </p> <h1 id="random-processes">Random Processes</h1> <p>Noise is modeled using random processes in continuous time. A random process $\mathbf{v}(t)$ defines a probability density at every time $t$.</p> <p>The autocovariance of a random process $\mathbf{v}(t)$ is given by \begin{equation} \text{cov}(\mathbf{v}(t_1), \mathbf{v}(t_2))=\mathbb{E}[\mathbf{v}(t_1)\mathbf{v}(t_2)^\text{T}] - \mathbb{E}[\mathbf{v}(t_1)]\mathbb{E}[\mathbf{v}(t_2)^\text{T}]. \end{equation}</p> <p>Essentially we take a bunch of samples at different times $t_1, t_2$, subtract the means at those times, and see how the results vary together.</p> <p>In the context of sensor noise, a commonly used assumption is that noise is a <em>wide sense stationary</em> random process, where the <em>mean</em> and <em>variance</em> of the process are independent of time.</p> <p>For a <em>wide sense stationary</em> process, the autocovariance $\text{cov}(\mathbf{v}(t_1), \mathbf{v}(t_2))$ <em>only</em> depends on the time difference $\tau =t_2-t_1$, \begin{equation} \text{cov}(\mathbf{v}(t_1), \mathbf{v}(t_2))=\mathbf{R}(t_2-t_1) = \mathbf{\tau}. \end{equation}</p> <p>The Power Spectral Density (PSD) of the process is given by \begin{equation} \mathbf{S}(j\omega)=\int_{-\infty}^\infty \mathbf{R}(\tau) \exp (-j\omega \tau) \text{d} \tau. \end{equation}</p> <p>The PSD describes the strength of the random process as different frequencies. For the scalar case, <em>white</em> noise is noise where the PSD is a constant for all frequencies, $\mathbf{S}(j\omega)=\mathbf{S}_w$. Technically, this kind of noise would have infinite power - but this works in practice.</p> <p>Using the inverse Fourier transform, white noise implies that the autocovariance is given by \begin{equation} \mathbf{R}_{\text{white}}(\tau)= \mathbf{S}_w \delta (\tau) = \mathbf{R}_c \delta (\tau). \end{equation} where $\delta(\tau)$ is the Dirac delta. For a long while I was confused by the fact that in sensor datasheets, the PSD is typically stated, and we read it off and use it as the continuous-time covariance for sensor noise. At first glance it does not make sense, since PSD is a frequency domain concept. However, with the assumption of white noise and a few lines of Fourier transforms, the PSD is shown to have the same value as the continuous-time noise covariance, denoted $\mathbf{R}_c$.</p> <h1 id="from-continuous-time-covariances-to-discrete-time">From Continuous-Time Covariances to Discrete Time</h1> <h2 id="linearize-then-discretize">Linearize Then Discretize</h2> <p>Consider a continuous-time system of the form \begin{equation} \dot{\mathbf{x}}=\mathbf{A}_c(t)\mathbf{x}(t)+\mathbf{L}_c(t)\mathbf{w}(t), \quad \mathbf{w}(t) \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_c \delta(\tau)) \end{equation}</p> <p>with $\mathbf{w}(t)$ being white noise, a Gaussian random process with continuous-time covariance $\mathbf{Q}_c$. This system may for instance come from linearization of a nonlinear system. The goal is to find an equivalent discrete-time system of the form</p> <p>\begin{equation} \mathbf{x}_{k+1}=\mathbf{A}_k \mathbf{x}_k + \mathbf{w}_k, \quad \mathbf{w}_k \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_d), \end{equation}</p> <p>which is more tractable to reason about on digital computers. The solution for $\mathbf{A}_k$ is fairly straightforward,</p> <p>\begin{equation} \mathbf{A}_k = \exp(\mathbf{A}_c \Delta t), \end{equation}</p> <p>where $\Delta t$ is the sampling period, and the matrix exponential is used. On the other hand, determining $\mathbf{Q}_d$ requires integration of the continuous-time dynamics to compute the discrete noise $\mathbf{w}_k$,</p> <p>\begin{equation} \mathbf{w}_k = \int_{-\infty}^\infty \exp (\mathbf{A} (t_{k+1}-\tau))\mathbf{L}_c (\tau) \mathbf{w}(\tau)\text{d}\tau \end{equation} The continuous-time covariance $\mathbf{Q}_d$ is then given by \begin{align} \mathbf{Q}_d&amp;=\mathbb{E}[\mathbf{w}_k \mathbf{w}_k^{\text{T}}], \end{align} which, after simplification, becomes </p> <p>\begin{equation} \mathbf{Q}_d = \int_{t_k}^{t_{k+1}} \exp(\mathbf{A_c}(t_{k+1}-\tau)) \mathbf{L}_c \mathbf{Q}_c \mathbf{L}_c^\text{T} \exp(\mathbf{A_c}(t_{k+1}-\tau))^{\text{T}} \text{d} \tau. \end{equation} </p> <p> The resulting $\mathbf{Q}_d$ is thus dependent on how the matrix exponential $\exp(\mathbf{A_c}(t_{k+1}-\tau))$ is computed. In some cases, it can be computed in closed form, giving an exact solution for $\mathbf{Q}_d$. It can also be approximated numerically using a Taylor series. The Taylor series approximation for $\exp(\mathbf{A}\Delta t)$ is given by </p> <p>\begin{equation} \exp(\mathbf{A}\Delta t)=\exp(\mathbf{A}_c\Delta t)=\mathbf{1}+\mathbf{A}_c\Delta t +\frac{1}{2}(\mathbf{A}_c\Delta t)^2+\frac{1}{3!}(\mathbf{A}_c\Delta t)^3 + \dots \end{equation} </p> <p>Using a zero’th order approximation, $\exp(\mathbf{A}_c\Delta t)\approx \mathbf{1}$, yields $\mathbf{Q}_d \approx \Delta t \mathbf{L}_c \mathbf{Q}_c \mathbf{L}_c^{\text{T}}$. Using the first four terms, a 3rd order Taylor series approximation, yields</p> <p>\begin{align} \mathbf{Q}_d&amp;\approx \mathbf{Q}_c\Delta t + (\mathbf{A}_c\mathbf{Q}_c + \mathbf{Q}_c \mathbf{A}_c^\text{T}) \frac{\Delta T^2}{2} +(\mathbf{A}_c^2\mathbf{Q}_c +2\mathbf{A}_c\mathbf{Q}_c\mathbf{A}^\text{T}+\mathbf{Q}(\mathbf{A}_c^\text{T})^2)\frac{\Delta T^3}{6}+ \nonumber \\ &amp;\quad(\mathbf{A}_c^3\mathbf{Q}_c+3\mathbf{A}_c^2\mathbf{Q}_c\mathbf{A}_c^\text{T} +3\mathbf{A}_c\mathbf{Q}_c(\mathbf{A}_c^\text{T})^2+\mathbf{Q}_c(\mathbf{A}_c^\text{T})^3)\frac{T^4}{24}. \end{align} </p> <h2 id="continuous-to-discrete-time-noise-in-a-vacuum">Continuous to Discrete Time Noise “In A Vacuum”</h2> <p>The above discussion is valid for a linear time varying system. This makes sense, for instance, when we linearize a nonlinear system and want to discretize the result. However, in some situations, we <em>already</em> have an exact discretization of the nonlinear system. In this situation, we <em>just</em> want the discrete-time analog of the continuous-time noise on the sensor, without looking at system dynamics - since we already have an exact discretization. For instance, consider the case of angular velocity kinematics with rotations,</p> <p>\begin{align} \dot{\mathbf{C}} &amp;= \mathbf{C} \boldsymbol{\omega}^\times \\ \mathbf{C}_{k+1} &amp;= \mathbf{C} \text{exp}({\Delta t\boldsymbol{\omega}_k}^\times), \end{align}</p> <p>where $\mathbf{C}$ is a cosine matrix describing the orientation of our robot, $\omega$ is an angular velocity measurement, and $\times$ is the cross product operator mapping to the Lie algebra of the space of rotations the $SO(3)$ group.</p> <p>The details are irrelevant and involve Lie groups, which is a big topic in and of itself. I have some <a href="/assets/pdf/notes/lie_group_doc.pdf">notes</a> on them and they are also covered in <d-cite key="barfoot2024state"></d-cite> and <d-cite key="sola2021microlietheorystate"></d-cite>. The point is that we have a real-world example where we have an exact discretization of the system already, without any assumptions on Taylor series truncations.</p> <p>The key aspect of this is that, in the section above, there are <em>two</em> discretizations happening. We are discretizing the linear time varying system <em>as well as</em> the continuous random process. However, in the current situation, we are <em>only</em> interested in the continuous random process. If we take the gyroscope noise with its given continuous-time noise characteristics, and we sample it at a given frequency: What will be the covariance on the resulting discrete-time sampled noise? This tends to be quite confusing, as in process noise derivations such as Sec. 4.7 of <d-cite key="farrell2008navigation"></d-cite> and Sec. 8.1.1 of <d-cite key="simon2006optimal"></d-cite> the linear system and random noise process discretizations are lumped in together. Sec. 8.1.2 of <d-cite key="simon2006optimal"></d-cite> is actually the relevant one for this.</p> <p>Formally, given Gaussian white noise \begin{equation} \mathbf{v}(t) \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_c \delta (t_1-t_2)), \end{equation}</p> <p>what is the “equivalent” discrete-time white noise \begin{equation} \mathbf{v}_k \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_d)? \end{equation}</p> <p>The “equivalent” is in quotes for good reason. For a Gaussian random process, <em>by definition</em>, \begin{equation} \mathbb{E}[\mathbf{v}(t_k) \mathbf{v}(t_k)^{\text{T}}] = \mathbb{E}[\mathbf{v}_k \mathbf{v}_k^{\text{T}}] = \mathbb{E}[\mathbf{Q}_c \delta (t_1-t_2)] = \mathbb{E}[\mathbf{Q}_c \delta (t_k-t_k)] = \mathbf{Q}_c. \end{equation}</p> <p>So, what is $\mathbf{v}_k$? It does not refer to the actual random process variable $\mathbf{v}(t_k)$. Rather, it refers to a separate $\mathbf{v}_k$ that behaves in a way that makes sense for us in an estimator.<br/> The widely used (and seemingly correct) answer is \begin{equation} \mathbf{Q}_d = \frac{\mathbf{Q}_c}{\Delta t}. \end{equation}</p> <p>However, tracking down exactly where it comes from and how it is derived is nontrivial. This is the equation given by <a href="https://github.com/ethz-asl/kalibr/wiki/IMU-Noise-Model">the IMU noise model section of Kalibr wiki</a>, which itself cites the appendix of J. Crassidis’ sigma point Kalman filtering paper <d-cite key="crassidis2006sigma"></d-cite>. The other source for this seem to be the 3D attitude estimation paper by N. Trawny and S. Roulemiotios <d-cite key="trawny2005indirect"></d-cite>, and Dan Simon’s optimal state estimation book <d-cite key="simon2006optimal"></d-cite>, which is itself the cited source in <d-cite key="trawny2005indirect"></d-cite>.</p> <h3 id="forward-euler-discretization-of-linear-system-and-direct-comparison">Forward Euler Discretization of Linear System And Direct Comparison</h3> <p>This derivation I have seen floating around, but I do not have a direct source for it. It’s the one that makes the most sense though.</p> <p>We take a linear system, discretize it using a forward Euler method, and then compare to the zero’th order approximation from the Linearize Then Discretize approach. We are thus able to separate the discretization of the system matrices from discretization of the random process.</p> <p>Formally, start with the, for now deterministic, linear system as follows. This corresponds to the first step of just discretizing the system matrices, without considering the random process aspect. Thus, for now, $\mathbf{v}$ is deterministic.</p> <p> \begin{align} \dot{\mathbf{x}}&amp;=\mathbf{A}_c \mathbf{x}+\mathbf{L}_c \mathbf{v}, \end{align} </p> <p>a forward Euler scheme with $\dot{\mathbf{x}}\approx \frac{\mathbf{x}_{k+1}-\mathbf{x}_k}{\Delta t}$ yields</p> <p> \begin{align} \mathbf{x}_{k+1}&amp;=\underbrace{(\mathbf{1}+\Delta t\mathbf{A}_c)}_{\mathbf{A}_d} \mathbf{x}_k+ \underbrace{\Delta t \mathbf{L}_c}_{\mathbf{L}_d} \mathbf{v}. \end{align} </p> <p>Now let us remember the fact that $\mathbf{v}$ is actually issued from a random process and consider the system</p> <p> \begin{align} \dot{\mathbf{x}}&amp;=\mathbf{A}_c \mathbf{x}+\mathbf{L}_c \mathbf{v}, \quad \mathbf{v} \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_c \delta (t_1-t_2)), \end{align} </p> <p>such that the equivalent discrete-time system is given by</p> <p> \begin{align} \mathbf{x}_{k+1}&amp;=\underbrace{(\mathbf{1}+\Delta t\mathbf{A}_c)}_{\mathbf{A}_d} \mathbf{x}_k+ \underbrace{\Delta t \mathbf{L}_c}_{\mathbf{L}_d} \mathbf{v}_k, \quad \mathbf{v}_k\sim \mathcal{N}(\mathbf{0}, \mathbf{R}_d), \end{align} </p> <p>where now $\mathbf{v}_k$ is its own Gaussian random variable, with yet to be determined $\mathbf{R}_d$. This is equivalent to</p> <p> \begin{align} \mathbf{x}_{k+1}&amp;=\mathbf{A}_d \mathbf{x}_k+\mathbf{w}_k, \quad \mathbf{w}_k\sim \mathcal{N}(\mathbf{0}, \mathbf{L}_d\mathbf{R}_d\mathbf{L}_d^T), \end{align} </p> <p>$\mathbf{R}_d$ is used for the covariance as $\mathbf{Q}_d$ has been reserved for the $\mathbf{w}_k$ from the Linearize then Discretize section. However, $\mathbf{w}_k$ now corresponds to the $\mathbf{w}_k$ from the Linearize then Discretize section. Using the zero’th order approximation for $\mathbf{Q}_d$ and comparing to the $\mathbf{L}_d\mathbf{R}_d\mathbf{L}_d^T$ expression we obtained here gives</p> <p> \begin{align} \mathbf{L}_d\mathbf{R}_d\mathbf{L}_d^T &amp;= \Delta t \mathbf{L}_c \mathbf{Q}_c \mathbf{L}_c^{\text{T}} \\ \Delta t^2 \mathbf{L}_c\mathbf{R}_d\mathbf{L}_c^T &amp;= \Delta t \mathbf{L}_c \mathbf{Q}_c \mathbf{L}_c^{\text{T}} \\ \mathbf{R}_d &amp;= \mathbf{Q}_c/\Delta t. \end{align} </p> <p>We have reverse engineered the covariance on just the sensor noise itself, $\mathbf{R}_d$, by considering a first-order forward Euler discretization to separate out the system matrix discretization from the random process discretization. We knew what the result of the overall discretization should be from the zeroth order approximation in the Linearize and Discretize section. Then we compared the results of the two approaches and matched the right matrices together.</p> <p>This is the approach that made the most sense to me. However, it is very much roundabout. It does not fully answer the question of “If I just have a nonlinear discrete system with continuous covariances specified for my sensor, what is the discrete time covariance?”. Rather we have to go through linearizations.</p> <h3 id="constant-covariance-estimate-for-a-static-system">Constant Covariance Estimate For A Static System</h3> <p>This is the argument of Sec. 8.1.2 of <d-cite key="simon2006optimal"></d-cite>. I have a few big issues with the chain of logic presented in there. If anyone has good answers to these, please let me know.</p> <p>The argument is essentially as follows. We are trying to isolate the effect of noise, so we take a discrete-time system whose state does not change, and whose measurement is directly equal to the state. This is like taking a gyroscope, putting it on a table (such that the true angular velocity does not change), and considering the resulting measurement. We then say that if we apply the Kalman filter to this system, the error covariance should not change, since there is nothing time-changing about the system. This implies a specific form for the discrete-time covariance, which ends up being the same as the continuous-to-discrete-time conversion we seek. Formally, we start with the scalar system</p> <p> \begin{align} x_k &amp;= x_{k-1} \\ y_k &amp;= x_k + v_k, \quad v_k \sim \mathcal{N}(0, R_d). \end{align} </p> <p>We then apply a Kalman filter to do a correction at a given timestep. There is no uncertainty in the process model, and the correction boils down to linking subsequent covariances as</p> <p> \begin{equation} P_{k+1}=\frac{P_k R_d}{P_k + R_d}. \end{equation} </p> <p>Right off the bat, my first problem with the argument. This only holds for the scalar case. But okay. This then implies that the covariance at timestep $k$ is given by</p> <p> \begin{equation} P_{k}=\frac{P_0 R_d}{kP_0+R_d}, \end{equation} </p> <p>and we want to manipulate this. This is where their argument goes completely off the rails, at least in my understanding. We take the following limit,</p> <p> \begin{equation} \lim_{P_0 \rightarrow \infty}P_{k}=\frac{R}{k}=\frac{R_dT}{k}. \end{equation} </p> <p>And this I completely do not understand. <strong><em>Why</em></strong> ?! Why do we have to push the initial covariance to infinity? How does this make sense? If someone understands please let me know. The argument then proceeds by setting \begin{equation} R_d=\frac{R_c}{T} \end{equation} to make the above expression independent of $T$.</p> <p>To be blunt, I do not think the argument presented in this book for the discrete to continuous time conversion (at least, when purely considering the measurement in Sec. 8.1.2) makes sense. It is possible I missed something major. If I did, please let me know by sending me a mail. That being said, this has a commonality with the previous approach, in that we specify the continuous-time to discrete-time covariance conversion based on behaviour we want from the estimator, and not from a pure mathematical consideration of the random process.</p> <h3 id="conclusion-for-continuous-to-discrete-time-noise-in-a-vacuum">Conclusion For Continuous to Discrete Time Noise “In A Vacuum”</h3> <p>I suspect there is no good explanation based on sampling or integrating the white-noise continuous Gaussian process. One can perhaps do some kind of averaging as mentioned in <a href="https://math.stackexchange.com/questions/3851352/is-there-a-continuous-time-stochastic-process-that-when-sampled-yields-discret">this Stack Overflow post.</a> However, purely in terms of sensor noise for a robot navigation sensor model, it seems there is no mathematically satisfying way to decouple the system dynamics from the random process. The best we can do is the forward Euler discretization comparison method.</p> ]]></content><author><name></name></author><summary type="html"><![CDATA[some bees in my bonnet on continuous-time to discrete-time white noise conversion]]></summary></entry><entry><title type="html">nonlinear noise in nonlinear-least-squares optimization</title><link href="https://vkorotkine.github.io/blog/2025/batch-noise-linearization/" rel="alternate" type="text/html" title="nonlinear noise in nonlinear-least-squares optimization"/><published>2025-03-19T00:00:00+00:00</published><updated>2025-03-19T00:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2025/batch-noise-linearization</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2025/batch-noise-linearization/"><![CDATA[<p>Batch optimization methods are ubiquitous in robotics. We would like to solve for some robot states given some measurements. To do this, we create an error that quantifies the difference between <strong><em>the measurement we expect</em></strong> (that depends on the state) and the <strong><em>the measurement we receive</em></strong> (a given value from a sensor, and does not depend on the robot state).</p> <p>Consider a single received measurement $\mathbf{y}$, the sensor model for which is $\mathbf{y}=\mathbf{g}(\mathbf{x})+\mathbf{v}$, where $\mathbf{v}\sim \mathcal{N}(\mathbf{0}, \mathbf{R})$ is Gaussian distributed noise with covariance $\mathbf{R}$. The robot state estimate is obtained by solving the Max A Posteriori problem \begin{equation} \hat{\mathbf{x}}=\text{argmax}_{\mathbf{x}} p(\mathbf{x}|\mathbf{y}), \end{equation}</p> <p>Since there are no priors, and discarding the normalization constant, Bayes’ rule leaves us with \begin{equation} \hat{\mathbf{x}}=\text{argmax}_{\mathbf{x}} p(\mathbf{y}|\mathbf{x}). \end{equation}</p> <p>which is equivalent to minimizing the negative log-likelihood as \begin{equation} \hat{\mathbf{x}}=\text{argmin}_{\mathbf{x}} -\log p(\mathbf{y}|\mathbf{x}). \end{equation}</p> <p>The form for $p(\mathbf{y}|\mathbf{x})$ is Gaussian, meaning that \begin{equation} p(\mathbf{y}|\mathbf{x}) = \alpha \exp(-(\mathbf{y}-\mathbf{g}(\mathbf{x}))^{\text{trans}}\mathbf{R}^{-1}(\mathbf{y}-\mathbf{g}(\mathbf{x}))), \end{equation}</p> <p>where $\alpha$ is a normalization constant. By defining $\mathbf{e}(\mathbf{x})=\mathbf{y}-\mathbf{g}(\mathbf{x})$, the negative log-likelihood minimization can be written \begin{equation} \hat{\mathbf{x}}=\text{argmin}_{\mathbf{x}} \mathbf{e}(\mathbf{x}) \mathbf{R}^{-1} \mathbf{e}(\mathbf{x}). \end{equation}</p> <p>This is pretty much in the nonlinear-least-squares form that is used by solvers such as Ceres. We linearize the error $\mathbf{e}(\mathbf{x})$ to construct successive Taylor series approximations to our loss and (hopefully) reach the minimum we want.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/linearization_everywhere-480.webp 480w,/assets/img/blogs/linearization_everywhere-800.webp 800w,/assets/img/blogs/linearization_everywhere-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blogs/linearization_everywhere.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A favorite engineering pastime. </div> <p>However, what happens when the noise enters nonlinearly into the measurement model? Formally, \begin{equation} \mathbf{y}=\mathbf{g}(\mathbf{x}, \mathbf{v}) \quad \mathbf{v}\sim \mathcal{N}(\mathbf{0}, \mathbf{R}). \end{equation}</p> <p>The measurement likelihood $p(\mathbf{y}|\mathbf{x})$ is non-Gaussian and forming the error \begin{equation} \mathbf{e}(\mathbf{x})=\mathbf{y}-\mathbf{g}(\mathbf{x}, \mathbf{v}), \end{equation}</p> <p>gets us nowhere. So we linearize and write \begin{equation} \mathbf{y}=\mathbf{g}(\mathbf{x}) + \mathbf{v}\quad \mathbf{v}\sim \mathcal{N}(\mathbf{0}, \mathbf{L} \mathbf{R} \mathbf{L}^{\text{T}}), \end{equation}</p> <p>where $\mathbf{L}$ is the Jacobian of the measurement model with respect to the noise variable evaluated at the current state estimate $\bar{\mathbf{x}}$, \begin{equation} \mathbf{L} = \left. \frac{\partial \mathbf{g}}{\partial \mathbf{x}}\right|_{\bar{\mathbf{x}}}. \end{equation}</p> <p>This is different from the linearization approximation that we use in methods like Gauss-Newton, where we first pose the problem then use iterative methods to solve it. <em>_before even going into the optimizer_</em> we make a linearization approximation to the loss. Whether this causes issues depends on the application. We can get funny situations where $\mathbf{L}$ is not full rank, causing a singular covariance. </p>]]></content><author><name></name></author><summary type="html"><![CDATA[linearization everywhere]]></summary></entry><entry><title type="html">useful resources</title><link href="https://vkorotkine.github.io/blog/2025/useful-resources/" rel="alternate" type="text/html" title="useful resources"/><published>2025-02-25T11:00:00+00:00</published><updated>2025-02-25T11:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2025/useful-resources</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2025/useful-resources/"><![CDATA[<p>The following is a small list of resources that I recommend to people occasionally.</p> <ul> <li>The <a href="https://www.incontrolpodcast.com/"> InControl podcast</a> hosted by Alberto Padoan. Control theory, math, robotics.</li> <li><a href="https://substack.com/@henryfarrell"> Henry Farrell’s substack</a>. Mix of policy and technology.</li> <li><a href="https://www.argmin.net/"> argmin blog</a> by Ben Recht. Optimization and machine learning.</li> <li><a href="https://hankyang.seas.harvard.edu/Semidefinite/"> Semidefinite optimization and relaxation book</a> by Heng Yang. Covers certifiably optimal algorithms in robotics.</li> <li><a href="https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-696.pdf"> An introduction to inertial navigation</a> by Oliver J. Woodman.</li> <li><a href="https://docs.google.com/document/d/e/2PACX-1vQTvxZkYPbOq3VYKCfAy8hKs4wjwLOF6z_7LT5vDkDSgVmcOto15-yzmOVOi8uAaGVkWoPCg2FNHD-v/pub"> How to Read a Research Paper </a> by Dmitry Berenson at University of Michigan. Written for the robotics field specifically.</li> <li><a href="https://rpg.ifi.uzh.ch/docs/IROS18_Zhang.pdf"> A Tutorial on Quantitative Trajectory Evaluation for Visual(-Inertial) Odometry </a> by Zichao Zhang and Davide Scaramuzza. Useful reference for error metrics in robot navigation.</li> <li>ROS Resources: <a href="http://wiki.ros.org/ROS/Tutorials"> ROS Tutorials </a>, <a href="https://rsl.ethz.ch/education-students/lectures/ros.html"> ETH ROS Course </a>, <a href="https://github.com/methylDragon/ros-tutorials"> methylDragon’s ros-tutorials on github. </a></li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[The following is a small list of resources that I recommend to people occasionally. The InControl podcast hosted by Alberto Padoan. Control theory, math, robotics. Henry Farrell’s substack. Mix of policy and technology. argmin blog by Ben Recht. Optimization and machine learning. Semidefinite optimization and relaxation book by Heng Yang. Covers certifiably optimal algorithms in robotics. An introduction to inertial navigation by Oliver J. Woodman. How to Read a Research Paper by Dmitry Berenson at University of Michigan. Written for the robotics field specifically. A Tutorial on Quantitative Trajectory Evaluation for Visual(-Inertial) Odometry by Zichao Zhang and Davide Scaramuzza. Useful reference for error metrics in robot navigation. ROS Resources: ROS Tutorials , ETH ROS Course , methylDragon’s ros-tutorials on github.]]></summary></entry><entry><title type="html">random code tidbits</title><link href="https://vkorotkine.github.io/blog/2025/python-float-formatters/" rel="alternate" type="text/html" title="random code tidbits"/><published>2025-01-30T11:00:00+00:00</published><updated>2025-01-30T11:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2025/python-float-formatters</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2025/python-float-formatters/"><![CDATA[<p>Random bits of code I reuse every so often.</p> <h2 id="python-function-tidbits">Python Function Tidbits</h2> <p>Formatting a Python float with a given number of significant figures,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">number</span> <span class="o">=</span> <span class="mf">1.2345</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number formatted to 2 decimal places: </span><span class="si">{</span><span class="n">number</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>Writing a string to file,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">my_string</span> <span class="o">=</span> <span class="sh">"</span><span class="s">lie_groups</span><span class="sh">"</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">Output.txt</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">my_string</span><span class="p">)</span>
</code></pre></div></div> <p>Read/write with pickle,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_dict</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">euler.pickle</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">wb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">test_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="p">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>

<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">euler.pickle</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">rb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div> <p>Number formats:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="sh">"</span><span class="s">.1e</span><span class="sh">"</span> <span class="c1">#: scientific notation with 1 decimal point (standard form)
</span><span class="sh">"</span><span class="s">.2f</span><span class="sh">"</span> <span class="c1">#: 2 decimal places
</span><span class="sh">"</span><span class="s">.3g</span><span class="sh">"</span> <span class="c1">#: 3 significant figures
</span><span class="sh">"</span><span class="s">.4%</span><span class="sh">"</span> <span class="c1">#: percentage with 4 decimal places
</span></code></pre></div></div> <p>with more details <a href="https://docs.python.org/3/library/string.html#formatspec">here</a>.</p> <h2 id="plotting">Plotting</h2> <p>Plotting timestamps as vertical lines,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">ax</span><span class="p">:</span> <span class="n">plt</span><span class="p">.</span><span class="n">Axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">vlines</span><span class="p">([</span><span class="n">stamps_rel_pos</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Measurement stamps</span><span class="sh">"</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="pandas-dataframe-manipulation">Pandas Dataframe Manipulation</h2> <p>Nicely formatting a multilevel pandas dataframe to input into a paper. Given a dataframe with columns Dims and Method, as well as some metrics of interest, we create a table that breaks down these metrics by Dims and Method.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>


<span class="k">def</span> <span class="nf">highlight_min</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">highlight_max</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    func : function
        ``func`` should take a Series if ``axis`` in [0,1] and return a list-like
        object of same length, or a Series, not necessarily of same length, with
        valid index labels considering ``subset``.
        ``func`` should take a DataFrame if ``axis`` is ``None`` and return either
        an ndarray with the same shape or a DataFrame, not necessarily of the same
        shape, with valid index and columns labels considering ``subset``.
    </span><span class="sh">"""</span>
    <span class="n">attr</span> <span class="o">=</span> <span class="sh">"</span><span class="s">textbf:--rwrap;</span><span class="sh">"</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">ndim</span>
    <span class="c1"># ndim = len(data.index.names)
</span>    <span class="k">if</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Series from .apply(axis=0) or axis=1
</span>        <span class="k">if</span> <span class="n">highlight_max</span> <span class="ow">is</span> <span class="bp">False</span><span class="p">:</span>
            <span class="n">is_min</span> <span class="o">=</span> <span class="n">data</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="nf">min</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">is_min</span> <span class="o">=</span> <span class="n">data</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span>
        <span class="n">ret_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">attr</span> <span class="k">if</span> <span class="n">v</span> <span class="k">else</span> <span class="sh">""</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">is_min</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">highlight_max</span> <span class="ow">is</span> <span class="bp">False</span><span class="p">:</span>
            <span class="n">is_min</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">transform</span><span class="p">(</span><span class="sh">"</span><span class="s">min</span><span class="sh">"</span><span class="p">)</span> <span class="o">==</span> <span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">is_min</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">transform</span><span class="p">(</span><span class="sh">"</span><span class="s">max</span><span class="sh">"</span><span class="p">)</span> <span class="o">==</span> <span class="n">data</span>
        <span class="n">ret_val</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">is_min</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="sh">""</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">columns</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">ret_val</span>


<span class="k">def</span> <span class="nf">format_multiindexed_df</span><span class="p">(</span>
    <span class="n">df_metric</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">floating_point_format_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">column_format</span><span class="o">=</span><span class="sh">"</span><span class="s">|*{7}{c|}</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">min_columns</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">max_columns</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">drop_columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">Dims</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NEES</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Method</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Run Name</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Case</span><span class="sh">"</span><span class="p">],</span>
<span class="p">):</span>

    <span class="n">df_metric</span> <span class="o">=</span> <span class="n">df_metric</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">drop_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">df_metric</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">drop_columns</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">min_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">df_styled</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">style</span> <span class="o">=</span> <span class="n">df_metric</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span>
            <span class="n">highlight_min</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="n">min_columns</span>
        <span class="p">)</span>
    <span class="n">df_styled</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">style</span> <span class="o">=</span> <span class="n">df_styled</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span>
        <span class="n">highlight_min</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="n">max_columns</span><span class="p">,</span> <span class="n">highlight_max</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

    <span class="n">df_styled</span> <span class="o">=</span> <span class="n">df_styled</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">floating_point_format_dict</span><span class="p">)</span>

    <span class="n">latex_string</span> <span class="o">=</span> <span class="n">df_styled</span><span class="p">.</span><span class="nf">to_latex</span><span class="p">(</span><span class="n">column_format</span><span class="o">=</span><span class="n">column_format</span><span class="p">,</span> <span class="n">hrules</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">latex_string</span> <span class="o">=</span> <span class="n">latex_string</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span>
        <span class="sh">"</span><span class="se">\\\n</span><span class="s">\end{tabular}</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="se">\\</span><span class="s"> \hline </span><span class="se">\n</span><span class="s">\end{tabular}</span><span class="sh">"</span>
    <span class="p">)</span>
    <span class="n">latex_string</span> <span class="o">=</span> <span class="n">latex_string</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span>
        <span class="sh">"</span><span class="se">\\\n</span><span class="s">\end{tabular}</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="se">\\</span><span class="s"> \hline </span><span class="se">\n</span><span class="s">\end{tabular}</span><span class="sh">"</span>
    <span class="p">)</span>

    <span class="c1"># latex_string = latex_string.replace("{r}", "{c|}")
</span>    <span class="n">latex_string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">"</span><span class="se">\\</span><span class="s">\.*rule</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="se">\\</span><span class="s">\hline</span><span class="sh">"</span><span class="p">,</span> <span class="n">latex_string</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">latex_string</span><span class="p">)</span>

<span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">MultiIndex</span><span class="p">.</span><span class="nf">from_frame</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="sh">"</span><span class="s">Dims</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Method</span><span class="sh">"</span><span class="p">]])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">{</span>
        <span class="sh">"</span><span class="s">Avg Iterations</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">Avg Iter.</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="nf">format_multiindexed_df</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">RMSE (deg)</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">{:,.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nb">format</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">RMSE (m)</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">{:,.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nb">format</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">ANEES</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">{:,.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nb">format</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">Time (s)</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">{:,.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nb">format</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">Avg Iter.</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">{:,.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nb">format</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="n">min_columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">RMSE (deg)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">RMSE (m)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">ANEES</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Avg Iter.</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Time (s)</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">max_columns</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
<span class="p">)</span>

</code></pre></div></div> <h3 id="cleaning-up-a-latex-paper-repository-before-submitting-to-arxiv">Cleaning up a LaTeX paper repository before submitting to arXiv</h3> <p>Removes unnecessary auxiliary files before uploading LaTeX code to arXiv. Be careful not to run this in the original repo, but rather a copy.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># DO NOT RUN THIS IN THE ORIGINAL. </span>
<span class="c"># RUN AFTER MOVING EVERYTHING TO THE NEW SUBMISSION DIRECTORY</span>
<span class="c">#!/bin/bash/</span>
<span class="nb">rm </span>main.log
<span class="nb">rm </span>main.pdf 
<span class="nb">rm </span>main.run.xml
<span class="nb">rm </span>main.synctex.gz 
<span class="nb">rm </span>main-blx.bib
<span class="nb">rm </span>main.aux
<span class="nb">rm </span>main.blg
<span class="nb">rm</span> <span class="nt">-rf</span> .git
<span class="nb">rm</span> <span class="nt">-rf</span> .vscode
<span class="nb">rm</span> .gitignore
<span class="nb">rm </span>main.fdb_latexmk
<span class="nb">rm </span>main.fls
<span class="nb">rm </span>clean_up_for_arxiv_v2.sh <span class="c"># Name of current script</span>
</code></pre></div></div> <h2 id="plotting-1">Plotting</h2> <p>Arranging plots in interesting configurations using GridSpec: <a href="https://gist.github.com/vkorotkine/b099da964335e23e22182bdeff68cdf8"> this github gist </a></p>]]></content><author><name></name></author><category term="code"/><summary type="html"><![CDATA[useful to have on hand]]></summary></entry><entry><title type="html">useful identities</title><link href="https://vkorotkine.github.io/blog/2021/identities/" rel="alternate" type="text/html" title="useful identities"/><published>2021-05-22T00:00:00+00:00</published><updated>2021-05-22T00:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2021/identities</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2021/identities/"><![CDATA[<p>The following is a random collection of identities and facts I encounter semi-regularly in my research.</p> <h2 id="lie-groups">Lie Groups</h2> <p>Lie groups are ubiquitous in robotics due to the need to handle rotations. If you are looking for a comprehensive introduction to the subject, <d-cite key="solà2021microlietheorystate"></d-cite> and <d-cite key="barfoot2024state"></d-cite> are classic resources.</p> <p>Fact 1: For the $SO(2)$ group of 2D rotations, the following holds, \begin{align} v^\wedge \mathbf{u} &amp;= \begin{bmatrix} 0 &amp; -v\\ v &amp; 0 \end{bmatrix} \begin{bmatrix} u_1 \\ u_2 \end{bmatrix} \\ &amp;= \begin{bmatrix} 0 &amp; -1 \\ 1 &amp; 0 \end{bmatrix} \begin{bmatrix} u_1 \\ u_2 \end{bmatrix} v \\ &amp;= \mathbf{P} \mathbf{u}v, \end{align} Where \(\mathbf{P}=\begin{bmatrix} 0 &amp; -1 \\\ 0 &amp; 1\end{bmatrix}\). This contrasts with the $SO(3)$ case, where \(\mathbf{v}^\wedge \mathbf{u} = -\mathbf{u}^\wedge \mathbf{v}\). This ties into the $\ \odot\ $ operator as described in <d-cite key="barfoot2024state"></d-cite> in the section covering homogeneous points.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[quick mathematical facts I rederive every so often]]></summary></entry></feed>