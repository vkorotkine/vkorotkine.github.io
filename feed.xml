<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://vkorotkine.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://vkorotkine.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-19T19:16:12+00:00</updated><id>https://vkorotkine.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">media recommendations</title><link href="https://vkorotkine.github.io/blog/2025/useful-resources/" rel="alternate" type="text/html" title="media recommendations"/><published>2025-02-25T11:00:00+00:00</published><updated>2025-02-25T11:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2025/useful-resources</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2025/useful-resources/"><![CDATA[<p>The following is a small list of resources that I recommend to people occasionally.</p> <ul> <li>The <a href="https://www.incontrolpodcast.com/"> InControl podcast</a> hosted by Alberto Padoan. Control theory, math, robotics.</li> <li><a href="https://substack.com/@henryfarrell"> Henry Farrell’s substack</a>. Mix of policy and technology.</li> <li><a href="https://www.argmin.net/"> argmin blog</a> by Ben Recht. Optimization and machine learning.</li> <li><a href="https://hankyang.seas.harvard.edu/Semidefinite/"> Semidefinite optimization and relaxation book</a> by Heng Yang. Covers certifiably optimal algorithms in robotics.</li> <li><a href="https://docs.google.com/document/d/e/2PACX-1vQTvxZkYPbOq3VYKCfAy8hKs4wjwLOF6z_7LT5vDkDSgVmcOto15-yzmOVOi8uAaGVkWoPCg2FNHD-v/pub"> How to Read a Research Paper </a> by Dmitry Berenson at University of Michigan. Written for the robotics field specifically.</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[The following is a small list of resources that I recommend to people occasionally. The InControl podcast hosted by Alberto Padoan. Control theory, math, robotics. Henry Farrell’s substack. Mix of policy and technology. argmin blog by Ben Recht. Optimization and machine learning. Semidefinite optimization and relaxation book by Heng Yang. Covers certifiably optimal algorithms in robotics. How to Read a Research Paper by Dmitry Berenson at University of Michigan. Written for the robotics field specifically.]]></summary></entry><entry><title type="html">random code tidbits</title><link href="https://vkorotkine.github.io/blog/2025/python-float-formatters/" rel="alternate" type="text/html" title="random code tidbits"/><published>2025-01-30T11:00:00+00:00</published><updated>2025-01-30T11:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2025/python-float-formatters</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2025/python-float-formatters/"><![CDATA[<p>I often forget the details of some basic Python syntax. The goal of this post is to collect them somewhere. It is a pure convenience post as these are easily googleable. I expand and refine on these as time allows.</p> <h2 id="python-function-tidbits">Python Function Tidbits</h2> <p>Formatting a Python float with a given number of significant figures,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">number</span> <span class="o">=</span> <span class="mf">1.2345</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number formatted to 2 decimal places: </span><span class="si">{</span><span class="n">number</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>Writing a string to file,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">my_string</span> <span class="o">=</span> <span class="sh">"</span><span class="s">lie_groups</span><span class="sh">"</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">Output.txt</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">my_string</span><span class="p">)</span>
</code></pre></div></div> <p>Read/write with pickle,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_dict</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">euler.pickle</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">wb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">test_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="p">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>

<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">euler.pickle</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">rb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div> <p>Number formats:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="sh">"</span><span class="s">.1e</span><span class="sh">"</span> <span class="c1">#: scientific notation with 1 decimal point (standard form)
</span><span class="sh">"</span><span class="s">.2f</span><span class="sh">"</span> <span class="c1">#: 2 decimal places
</span><span class="sh">"</span><span class="s">.3g</span><span class="sh">"</span> <span class="c1">#: 3 significant figures
</span><span class="sh">"</span><span class="s">.4%</span><span class="sh">"</span> <span class="c1">#: percentage with 4 decimal places
</span></code></pre></div></div> <p>with more details <a href="https://docs.python.org/3/library/string.html#formatspec">here</a>.</p> <h2 id="plotting">Plotting</h2> <p>Plotting timestamps as vertical lines,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">ax</span><span class="p">:</span> <span class="n">plt</span><span class="p">.</span><span class="n">Axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">vlines</span><span class="p">([</span><span class="n">stamps_rel_pos</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Measurement stamps</span><span class="sh">"</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="pandas-dataframe-manipulation">Pandas Dataframe Manipulation</h2> <p>Nicely formatting a multilevel pandas dataframe to input into a paper. Given a dataframe with columns Dims and Method, as well as some metrics of interest, we create a table that breaks down these metrics by Dims and Method.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>


<span class="k">def</span> <span class="nf">highlight_min</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">highlight_max</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    func : function
        ``func`` should take a Series if ``axis`` in [0,1] and return a list-like
        object of same length, or a Series, not necessarily of same length, with
        valid index labels considering ``subset``.
        ``func`` should take a DataFrame if ``axis`` is ``None`` and return either
        an ndarray with the same shape or a DataFrame, not necessarily of the same
        shape, with valid index and columns labels considering ``subset``.
    </span><span class="sh">"""</span>
    <span class="n">attr</span> <span class="o">=</span> <span class="sh">"</span><span class="s">textbf:--rwrap;</span><span class="sh">"</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">ndim</span>
    <span class="c1"># ndim = len(data.index.names)
</span>    <span class="k">if</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Series from .apply(axis=0) or axis=1
</span>        <span class="k">if</span> <span class="n">highlight_max</span> <span class="ow">is</span> <span class="bp">False</span><span class="p">:</span>
            <span class="n">is_min</span> <span class="o">=</span> <span class="n">data</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="nf">min</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">is_min</span> <span class="o">=</span> <span class="n">data</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span>
        <span class="n">ret_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">attr</span> <span class="k">if</span> <span class="n">v</span> <span class="k">else</span> <span class="sh">""</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">is_min</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">highlight_max</span> <span class="ow">is</span> <span class="bp">False</span><span class="p">:</span>
            <span class="n">is_min</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">transform</span><span class="p">(</span><span class="sh">"</span><span class="s">min</span><span class="sh">"</span><span class="p">)</span> <span class="o">==</span> <span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">is_min</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">transform</span><span class="p">(</span><span class="sh">"</span><span class="s">max</span><span class="sh">"</span><span class="p">)</span> <span class="o">==</span> <span class="n">data</span>
        <span class="n">ret_val</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">is_min</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="sh">""</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">columns</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">ret_val</span>


<span class="k">def</span> <span class="nf">format_multiindexed_df</span><span class="p">(</span>
    <span class="n">df_metric</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">floating_point_format_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">column_format</span><span class="o">=</span><span class="sh">"</span><span class="s">|*{7}{c|}</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">min_columns</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">max_columns</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">drop_columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">Dims</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NEES</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Method</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Run Name</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Case</span><span class="sh">"</span><span class="p">],</span>
<span class="p">):</span>

    <span class="n">df_metric</span> <span class="o">=</span> <span class="n">df_metric</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">drop_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">df_metric</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">drop_columns</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">min_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">df_styled</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">style</span> <span class="o">=</span> <span class="n">df_metric</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span>
            <span class="n">highlight_min</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="n">min_columns</span>
        <span class="p">)</span>
    <span class="n">df_styled</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">style</span> <span class="o">=</span> <span class="n">df_styled</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span>
        <span class="n">highlight_min</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="n">max_columns</span><span class="p">,</span> <span class="n">highlight_max</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

    <span class="n">df_styled</span> <span class="o">=</span> <span class="n">df_styled</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">floating_point_format_dict</span><span class="p">)</span>

    <span class="n">latex_string</span> <span class="o">=</span> <span class="n">df_styled</span><span class="p">.</span><span class="nf">to_latex</span><span class="p">(</span><span class="n">column_format</span><span class="o">=</span><span class="n">column_format</span><span class="p">,</span> <span class="n">hrules</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">latex_string</span> <span class="o">=</span> <span class="n">latex_string</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span>
        <span class="sh">"</span><span class="se">\\\n</span><span class="s">\end{tabular}</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="se">\\</span><span class="s"> \hline </span><span class="se">\n</span><span class="s">\end{tabular}</span><span class="sh">"</span>
    <span class="p">)</span>
    <span class="n">latex_string</span> <span class="o">=</span> <span class="n">latex_string</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span>
        <span class="sh">"</span><span class="se">\\\n</span><span class="s">\end{tabular}</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="se">\\</span><span class="s"> \hline </span><span class="se">\n</span><span class="s">\end{tabular}</span><span class="sh">"</span>
    <span class="p">)</span>

    <span class="c1"># latex_string = latex_string.replace("{r}", "{c|}")
</span>    <span class="n">latex_string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">"</span><span class="se">\\</span><span class="s">\.*rule</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="se">\\</span><span class="s">\hline</span><span class="sh">"</span><span class="p">,</span> <span class="n">latex_string</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">latex_string</span><span class="p">)</span>

<span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">MultiIndex</span><span class="p">.</span><span class="nf">from_frame</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="sh">"</span><span class="s">Dims</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Method</span><span class="sh">"</span><span class="p">]])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">{</span>
        <span class="sh">"</span><span class="s">Avg Iterations</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">Avg Iter.</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="nf">format_multiindexed_df</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">RMSE (deg)</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">{:,.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nb">format</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">RMSE (m)</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">{:,.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nb">format</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">ANEES</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">{:,.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nb">format</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">Time (s)</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">{:,.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nb">format</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">Avg Iter.</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">{:,.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nb">format</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="n">min_columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">RMSE (deg)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">RMSE (m)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">ANEES</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Avg Iter.</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Time (s)</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">max_columns</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
<span class="p">)</span>

</code></pre></div></div>]]></content><author><name></name></author><category term="code"/><summary type="html"><![CDATA[useful to have on hand]]></summary></entry><entry><title type="html">useful identities</title><link href="https://vkorotkine.github.io/blog/2021/identities/" rel="alternate" type="text/html" title="useful identities"/><published>2021-05-22T00:00:00+00:00</published><updated>2021-05-22T00:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2021/identities</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2021/identities/"><![CDATA[<p>The following is a random collection of identities and facts I encounter semi-regularly in my research.</p> <h2 id="lie-groups">Lie Groups</h2> <p>Lie groups are ubiquitous in robotics due to the need to handle rotations. If you are looking for a comprehensive introduction to the subject, <d-cite key="solà2021microlietheorystate"></d-cite> and <d-cite key="barfoot2024state"></d-cite> are classic resources.</p> <p>Fact 1: For the $SO(2)$ group of 2D rotations, the following holds, \begin{align} v^\wedge \mathbf{u} &amp;= \begin{bmatrix} 0 &amp; -v\\ v &amp; 0 \end{bmatrix} \begin{bmatrix} u_1 \\ u_2 \end{bmatrix} \\ &amp;= \begin{bmatrix} 0 &amp; -1 \\ 1 &amp; 0 \end{bmatrix} \begin{bmatrix} u_1 \\ u_2 \end{bmatrix} v \\ &amp;= \mathbf{P} \mathbf{u}v, \end{align} Where \(\mathbf{P}=\begin{bmatrix} 0 &amp; -1 \\\ 0 &amp; 1\end{bmatrix}\). This contrasts with the $SO(3)$ case, where \(\mathbf{v}^\wedge \mathbf{u} = -\mathbf{u}^\wedge \mathbf{v}\). This ties into the $\ \odot\ $ operator as described in <d-cite key="barfoot2024state"></d-cite> in the section covering homogeneous points.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[quick mathematical facts I rederive every so often]]></summary></entry><entry><title type="html">noise in batch models that enters nonlinearly</title><link href="https://vkorotkine.github.io/blog/2021/batch-noise-linearization/" rel="alternate" type="text/html" title="noise in batch models that enters nonlinearly"/><published>2021-05-22T00:00:00+00:00</published><updated>2021-05-22T00:00:00+00:00</updated><id>https://vkorotkine.github.io/blog/2021/batch-noise-linearization</id><content type="html" xml:base="https://vkorotkine.github.io/blog/2021/batch-noise-linearization/"><![CDATA[<p>Batch optimization methods are ubiquitous in robotics. We would like to solve for some robot states given some measurements. To do this, we create an error that quantifies the difference between <strong><em>the measurement we expect</em></strong> (that depends on the state) and the <strong><em>the measurement we receive</em></strong> (a given value from a sensor, and does not depend on the robot state).</p> <p>Consider a single received measurement $\mathbf{y}$, the sensor model for which is $\mathbf{y}=\mathbf{g}(\mathbf{x})+\mathbf{v}$, where $\mathbf{v}\sim \mathcal{N}(\mathbf{0}, \mathbf{R})$ is Gaussian distributed noise with covariance $\mathbf{R}$. The robot state estimate is obtained by solving the Max A Posteriori problem \begin{equation} \hat{\mathbf{x}}=\text{argmax}_{\mathbf{x}} p(\mathbf{x}|\mathbf{y}), \end{equation}</p> <p>Since there are no priors, and discarding the normalization constant, Bayes’ rule leaves us with \begin{equation} \hat{\mathbf{x}}=\text{argmax}_{\mathbf{x}} p(\mathbf{y}|\mathbf{x}). \end{equation}</p> <p>which is equivalent to minimizing the negative log-likelihood as \begin{equation} \hat{\mathbf{x}}=\text{argmin}_{\mathbf{x}} -\log p(\mathbf{y}|\mathbf{x}). \end{equation}</p> <p>The form for $p(\mathbf{y}|\mathbf{x})$ is Gaussian, meaning that \begin{equation} p(\mathbf{y}|\mathbf{x}) = \alpha \exp(-(\mathbf{y}-\mathbf{g}(\mathbf{x}))\mathbf{R}^{-1}(\mathbf{y}-\mathbf{g}(\mathbf{x}))), \end{equation}</p> <p>where $\alpha$ is a normalization constant. By defining $\mathbf{e}(\mathbf{x})=\mathbf{y}-\mathbf{g}(\mathbf{x})$, the negative log-likelihood minimization can be written \begin{equation} \hat{\mathbf{x}}=\text{argmin}_{\mathbf{x}} \mathbf{e}(\mathbf{x}) \mathbf{R}^{-1} \mathbf{e}(\mathbf{x}). \end{equation}</p> <p>This is pretty much in the nonlinear-least-squares form that is used by solvers such as Ceres. We linearize the error $\mathbf{e}(\mathbf{x})$ to construct successive Taylor series approximations to our loss and (hopefully) reach the minimum we want.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/linearization_everywhere-480.webp 480w,/assets/img/blogs/linearization_everywhere-800.webp 800w,/assets/img/blogs/linearization_everywhere-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blogs/linearization_everywhere.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A favorite engineering pastime. </div> <p>However, what happens when the noise enters nonlinearly into the measurement model? Formally, \begin{equation} \mathbf{y}=\mathbf{g}(\mathbf{x}, \mathbf{v}) \quad \mathbf{v}\sim \mathcal{N}(\mathbf{0}, \mathbf{R}). \end{equation}</p> <p>The measurement likelihood $p(\mathbf{y}|\mathbf{x})$ is non-Gaussian and forming the error \begin{equation} \mathbf{e}(\mathbf{x})=\mathbf{y}-\mathbf{g}(\mathbf{x}, \mathbf{v}), \end{equation}</p> <p>gets us nowhere. So we linearize and write \begin{equation} \mathbf{y}=\mathbf{g}(\mathbf{x}) + \mathbf{v}\quad \mathbf{v}\sim \mathcal{N}(\mathbf{0}, \mathbf{L} \mathbf{R} \mathbf{L}^{\text{T}}), \end{equation}</p> <p>where $\mathbf{L}$ is the Jacobian of the measurement model with respect to the noise variable evaluated at the current state estimate $\bar{\mathbf{x}}$, \begin{equation} \mathbf{L} = \left. \frac{\partial \mathbf{g}}{\partial \mathbf{x}}\right|_{\bar{\mathbf{x}}}. \end{equation}</p> <p>This is different from the linearization approximation that we use in methods like Gauss-Newton, where we first pose the problem then use iterative methods to solve it. <em>_before even going into the optimizer_</em> we make a linearization approximation to the loss. Whether this causes issues depends on the application. We can get funny situations where $\mathbf{L}$ is not full rank, causing a singular covariance. </p>]]></content><author><name></name></author><summary type="html"><![CDATA[linearization everywhere]]></summary></entry></feed>